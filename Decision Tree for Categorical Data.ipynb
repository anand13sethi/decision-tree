{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             sales  salary  left\n",
      "2       accounting     low     1\n",
      "3            sales  medium     0\n",
      "5        technical  medium     0\n",
      "17           sales  medium     0\n",
      "18           RandD     low     0\n",
      "27       technical    high     0\n",
      "28     product_mng  medium     0\n",
      "37       marketing  medium     0\n",
      "40           sales  medium     0\n",
      "46       technical  medium     0\n",
      "48       technical  medium     0\n",
      "49           sales     low     0\n",
      "50       technical     low     0\n",
      "57         support    high     1\n",
      "72       technical  medium     0\n",
      "76       marketing    high     1\n",
      "82           sales  medium     0\n",
      "96      accounting     low     0\n",
      "124        support     low     1\n",
      "129      technical  medium     0\n",
      "132      technical     low     0\n",
      "137      technical     low     1\n",
      "140      technical  medium     0\n",
      "146          sales     low     0\n",
      "151          sales     low     0\n",
      "153      technical    high     0\n",
      "160      marketing     low     1\n",
      "169             IT     low     0\n",
      "171      technical  medium     0\n",
      "172          sales  medium     0\n",
      "...            ...     ...   ...\n",
      "11095        sales     low     0\n",
      "11101        RandD     low     0\n",
      "11102           IT  medium     0\n",
      "11103        sales     low     0\n",
      "11107    technical    high     0\n",
      "11111    technical     low     0\n",
      "11119           hr     low     1\n",
      "11129  product_mng     low     0\n",
      "11132   accounting  medium     0\n",
      "11138        RandD     low     0\n",
      "11140        sales     low     0\n",
      "11141           IT     low     0\n",
      "11146      support     low     1\n",
      "11149           hr  medium     0\n",
      "11151        sales  medium     1\n",
      "11154    marketing  medium     0\n",
      "11158        sales  medium     0\n",
      "11159  product_mng    high     0\n",
      "11166           IT  medium     0\n",
      "11171        RandD    high     0\n",
      "11174      support  medium     0\n",
      "11176   accounting     low     0\n",
      "11177        sales     low     0\n",
      "11178      support  medium     0\n",
      "11197           IT     low     0\n",
      "11200      support  medium     0\n",
      "11203      support  medium     0\n",
      "11224      support     low     1\n",
      "11231        RandD     low     0\n",
      "11235   accounting  medium     0\n",
      "\n",
      "[2248 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "# print(data.iloc[:,0:2]) #iloc to index the columns\n",
    "\n",
    "# frac - specifies 80%\n",
    "# random_state - it saves the current state of the split. Used for reproducability\n",
    "# Spliting data int Train-Validation[80-20]\n",
    "train = data.sample(frac=0.8, random_state=200) \n",
    "validation = data.drop(train.index)\n",
    "categorical_train_data = train.iloc[:, 7:10]\n",
    "categorical_validation_data = validation.iloc[:, 7:10]\n",
    "print(categorical_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy():\n",
    "    target = categorical_train_data.keys()[-1] # target -> Labels\n",
    "    entropy = 0\n",
    "    values = categorical_train_data[target].unique() # Finds the unique values in target variable, i.e. [0, 1]\n",
    "    for value in values:\n",
    "        '''\n",
    "            total count of 0's         total count of 1's\n",
    "            -------------------   ,    ---------------------  = frac\n",
    "            total numbers of rows      total number of rows\n",
    "        '''\n",
    "        frac = categorical_train_data[target].value_counts()[value]/len(categorical_train_data[target])\n",
    "        entropy += -frac*np.log2(frac)\n",
    "    return(entropy) # returns entropy of whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7932274601977748"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_info_attribute(attribute):\n",
    "    target = categorical_train_data.keys()[-1]\n",
    "    variables = categorical_train_data[attribute].unique() # get unique variables in specified attribute\n",
    "    target_variables = categorical_train_data[target].unique() # get unique in target, i.e. [0, 1]\n",
    "    info = 0\n",
    "    for v in variables:\n",
    "        entropy = 0\n",
    "        for target_v in target_variables:\n",
    "            n = len(categorical_train_data[attribute][categorical_train_data[attribute] == v][categorical_train_data[target] == target_v])\n",
    "            d = len(categorical_train_data[attribute][categorical_train_data[attribute] == v])\n",
    "            frac1 = n/(d + np.finfo(float).eps) # eps - smallest representable number such that 1.0 + eps != 1.0\n",
    "            entropy += -frac1 * np.log2(frac1)\n",
    "        frac2 = d/len(categorical_train_data)\n",
    "        info += -frac2 * entropy\n",
    "    return abs(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner_attribute():\n",
    "    info_gain = []\n",
    "    for attribute in categorical_train_data.keys()[:-1]:\n",
    "        info_gain.append(calc_entropy - calc_info_attribute(attribute))\n",
    "    return categorical_train_data.keys()[:-1][np.argmax(info_gain)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
